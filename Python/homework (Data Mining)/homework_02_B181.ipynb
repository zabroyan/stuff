{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 7. prosince)\n",
    "\n",
    "  * V rámci tohoto úkolu se musíte vypořádat s příznaky, které jsou různých typů.\n",
    "  * Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu.\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=1, suppress=True)\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "#display(data.shape)\n",
    "#display(data.head())\n",
    "#display(data.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zahodim priznaky:\n",
    "    name protoze je skoro unikatni pro kazdeho cloveka;\n",
    "    ticket protoze cislo listku nema zadny vliv na preziti;\n",
    "    home.dest ze stejneho duvodu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(columns = ['ID', 'name', 'ticket', 'home.dest'])\n",
    "string_cols = df.select_dtypes(['object']).columns\n",
    "\n",
    "for col in string_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "df[string_cols] = df[string_cols].apply(lambda x: x.cat.codes)\n",
    "\n",
    "xdata = df.drop(columns = ['survived'])\n",
    "ydata = df.loc[:, ['survived']]\n",
    "\n",
    "xdata = xdata.replace(np.nan, 0)\n",
    "xdata.loc[xdata.cabin==-1,'cabin'] = 0\n",
    "xdata.loc[xdata.embarked==-1,'embarked'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_seed = 333\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(xdata, ydata, test_size=0.25, random_state=rd_seed) \n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.25, random_state=rd_seed) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.798932\n",
      "accuracy score (validation): 0.835106\n",
      "accuracy score (test): 0.828000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import sklearn.metrics as metrics\n",
    "param_grid = {\n",
    "    'max_depth': range(1,51), \n",
    "    'criterion': ['entropy', 'gini']\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "\n",
    "val_acc = []\n",
    "train_acc = []\n",
    "for params in param_comb:\n",
    "    dt = DecisionTreeClassifier(**params)\n",
    "    dt.fit(Xtrain, ytrain)\n",
    "    val_acc.append(metrics.accuracy_score(yval, dt.predict(Xval)))\n",
    "\n",
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "\n",
    "dt = DecisionTreeClassifier(**best_params)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, dt.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, dt.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, dt.predict(Xtest))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, dt.predict(Xval))] = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regressor / Random Forest Regressor / AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.830961\n",
      "accuracy score (validation): 0.771277\n",
      "accuracy score (test): 0.772000\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "param_grid = {\n",
    "    'max_depth': range(1,50)\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    dtr = DecisionTreeRegressor(**params)\n",
    "    dtr.fit(Xtrain, ytrain)\n",
    "    val_acc.append(math.sqrt(metrics.mean_squared_error(yval, dtr.predict(Xval))))\n",
    "best_params = param_comb[np.argmin(val_acc)]\n",
    "dtr = DecisionTreeRegressor(**best_params)\n",
    "dtr.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, dtr.predict(Xtrain).round(0))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, dtr.predict(Xval).round(0))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, dtr.predict(Xtest).round(0))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, dtr.predict(Xval).round(0))] = dtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.852313\n",
      "accuracy score (validation): 0.819149\n",
      "accuracy score (test): 0.832000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': range(1,100,5),\n",
    "    'max_depth': range(1,5)\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    rfr = RandomForestRegressor(**params)\n",
    "    rfr.fit(Xtrain, ytrain)\n",
    "    val_acc.append(math.sqrt(metrics.mean_squared_error(yval, rfr.predict(Xval))))\n",
    "best_params = param_comb[np.argmin(val_acc)]\n",
    "rfr = RandomForestRegressor(**best_params)\n",
    "rfr.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, rfr.predict(Xtrain).round(0))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, rfr.predict(Xval).round(0))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, rfr.predict(Xtest).round(0))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, rfr.predict(Xval).round(0))] = rfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.816726\n",
      "accuracy score (validation): 0.803191\n",
      "accuracy score (test): 0.820000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': range(1,100,5),\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5, 1]\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    abr = AdaBoostRegressor(**params)\n",
    "    abr.fit(Xtrain, ytrain)\n",
    "    val_acc.append(math.sqrt(metrics.mean_squared_error(yval, abr.predict(Xval))))\n",
    "best_params = param_comb[np.argmin(val_acc)]\n",
    "abr = AdaBoostRegressor(**best_params)\n",
    "abr.fit(Xtrain, ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, abr.predict(Xtrain).round(0))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, abr.predict(Xval).round(0))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, abr.predict(Xtest).round(0))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, abr.predict(Xval).round(0))] = abr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.699288\n",
      "accuracy score (validation): 0.670213\n",
      "accuracy score (test): 0.624000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "param_grid = {\n",
    "    'n_clusters': range(1,10),\n",
    "    'init': ['k-means++', 'random'],\n",
    "    'random_state': range(1,5)\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    knn = KMeans(**params).fit(Xtrain, ytrain)\n",
    "    val_acc.append(metrics.accuracy_score(yval, knn.predict(Xval)))\n",
    "\n",
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "knn = KMeans(**best_params).fit(Xtrain,ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, knn.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, knn.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, knn.predict(Xtest))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, knn.predict(Xval))] = knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Neighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.973310\n",
      "accuracy score (validation): 0.771277\n",
      "accuracy score (test): 0.780000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "param_grid = {\n",
    "    'n_neighbors' : range(1,21),\n",
    "    'p': range(1,5),\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "\n",
    "Xtrain_knn = Xtrain.copy() \n",
    "Xtest_knn = Xtest.copy() \n",
    "Xval_knn = Xval.copy()\n",
    "\n",
    "Xtrain_knn = (Xtrain_knn - Xtrain_knn.min(axis=0))/(Xtrain_knn.max(axis=0) - Xtrain_knn.min(axis=0))\n",
    "Xtest_knn = (Xtest_knn - Xtest_knn.min(axis=0))/(Xtest_knn.max(axis=0) - Xtest_knn.min(axis=0))\n",
    "Xval_knn = (Xval_knn - Xval_knn.min(axis=0))/(Xval_knn.max(axis=0) - Xval_knn.min(axis=0))\n",
    "\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    kNN = KNeighborsRegressor(**params).fit(Xtrain_knn, ytrain)\n",
    "    val_acc.append(metrics.accuracy_score(yval, knn.predict(Xval_knn)))\n",
    "\n",
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "\n",
    "kNN = KNeighborsRegressor(**best_params)\n",
    "Xtest_knn.fillna(0, inplace=True)\n",
    "\n",
    "kNN.fit(Xtrain_knn, ytrain)\n",
    "\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, kNN.predict(Xtrain_knn).round(0))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, kNN.predict(Xval_knn).round(0))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, kNN.predict(Xtest_knn).round(0))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, kNN.predict(Xval_knn).round(0))] = kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.794000\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import logsumexp\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "pclass = np.array(xdata['pclass']).reshape(-1,1)\n",
    "x0 = OneHotEncoder(sparse = False).fit_transform(pclass)\n",
    "age = np.array(xdata['age']).reshape(-1,1)\n",
    "x1 = OneHotEncoder(sparse = False).fit_transform(age)\n",
    "sibsp = np.array(xdata['sibsp']).reshape(-1,1)\n",
    "x2 = OneHotEncoder(sparse = False).fit_transform(sibsp)\n",
    "parch = np.array(xdata['parch']).reshape(-1,1)\n",
    "x3 = OneHotEncoder(sparse = False).fit_transform(parch)\n",
    "fare = np.array(xdata['fare']).reshape(-1,1)\n",
    "x4 = OneHotEncoder(sparse = False).fit_transform(fare)\n",
    "cabin = np.array(xdata['cabin']).reshape(-1,1)\n",
    "x5 = OneHotEncoder(sparse = False).fit_transform(cabin)\n",
    "embarked = np.array(xdata['embarked']).reshape(-1,1)\n",
    "x6 = OneHotEncoder(sparse = False).fit_transform(embarked)\n",
    "x7 = np.array(xdata.sex).reshape(-1,1)\n",
    "\n",
    "data = np.concatenate([x0,x7,x1,x2,x3,x4,x5,x6], axis=1)\n",
    "clf = BernoulliNB(fit_prior = False).fit(data, ydata)\n",
    "pred = np.array([clf.predict(data)])\n",
    "print('accuracy score: {0:.6f}'.format(metrics.accuracy_score(ydata, clf.predict(data))))\n",
    "\n",
    "models[metrics.accuracy_score(ydata, clf.predict(data))] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.782918\n",
      "accuracy score (validation): 0.813830\n",
      "accuracy score (test): 0.812000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression().fit(Xtrain,ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, lr.predict(Xtrain).round(0))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, lr.predict(Xval).round(0))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, lr.predict(Xtest).round(0))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, lr.predict(Xval).round(0))] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (train): 0.788256\n",
      "accuracy score (validation): 0.829787\n",
      "accuracy score (test): 0.820000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'random_state': range(1,5),\n",
    "    'max_iter': range(1,100)\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n",
    "val_acc = []\n",
    "for params in param_comb:\n",
    "    lgr = LogisticRegression(**params).fit(Xtrain, ytrain)\n",
    "    val_acc.append(metrics.accuracy_score(yval, lgr.predict(Xval)))\n",
    "\n",
    "best_params = param_comb[np.argmax(val_acc)]\n",
    "lgr = LogisticRegression(**best_params).fit(Xtrain,ytrain)\n",
    "print('accuracy score (train): {0:.6f}'.format(metrics.accuracy_score(ytrain, lgr.predict(Xtrain))))\n",
    "print('accuracy score (validation): {0:.6f}'.format(metrics.accuracy_score(yval, lgr.predict(Xval))))\n",
    "print('accuracy score (test): {0:.6f}'.format(metrics.accuracy_score(ytest, lgr.predict(Xtest))))\n",
    "\n",
    "models[metrics.accuracy_score(yval, lgr.predict(Xval))] = lgr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nejlepsi model je  DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "s presnosti  84.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  survived\n",
       "0  1000         0\n",
       "1  1001         0\n",
       "2  1002         0\n",
       "3  1003         1\n",
       "4  1004         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation = pd.read_csv('evaluation.csv')\n",
    "ev = evaluation.drop(columns = ['ID', 'name', 'ticket', 'home.dest'])\n",
    "string_cols = ev.select_dtypes(['object']).columns\n",
    "for col in string_cols:\n",
    "    ev[col] = ev[col].astype('category')\n",
    "ev[string_cols] = ev[string_cols].apply(lambda x: x.cat.codes)\n",
    "ev = ev.replace(np.nan, 0)\n",
    "ev.loc[ev.cabin==-1,'cabin'] = 0\n",
    "ev.loc[ev.embarked==-1,'embarked'] = 3\n",
    "model = models[max(models)]\n",
    "print(\"Nejlepsi model je \", model)\n",
    "print(\"s presnosti \", (max(models)*100).round(0), \"%\")\n",
    "\n",
    "if model == clf:\n",
    "    pclass = np.array(ev['pclass']).reshape(-1,1)\n",
    "    x0 = OneHotEncoder(sparse = False).fit_transform(pclass)\n",
    "    age = np.array(ev['age']).reshape(-1,1)\n",
    "    x1 = OneHotEncoder(sparse = False).fit_transform(age)\n",
    "    sibsp = np.array(ev['sibsp']).reshape(-1,1)\n",
    "    x2 = OneHotEncoder(sparse = False).fit_transform(sibsp)\n",
    "    parch = np.array(ev['parch']).reshape(-1,1)\n",
    "    x3 = OneHotEncoder(sparse = False).fit_transform(parch)\n",
    "    fare = np.array(ev['fare']).reshape(-1,1)\n",
    "    x4 = OneHotEncoder(sparse = False).fit_transform(fare)\n",
    "    cabin = np.array(ev['cabin']).reshape(-1,1)\n",
    "    x5 = OneHotEncoder(sparse = False).fit_transform(cabin)\n",
    "    embarked = np.array(ev['embarked']).reshape(-1,1)\n",
    "    x6 = OneHotEncoder(sparse = False).fit_transform(embarked)\n",
    "    x7 = np.array(ev.sex).reshape(-1,1)\n",
    "\n",
    "    data = np.concatenate([x0,x7,x1,x2,x3,x4,x5,x6], axis=1)\n",
    "    survived = np.array(model.predict(data)).T\n",
    "else:\n",
    "    survived = model.predict(ev).round(0)\n",
    "    \n",
    "ID = evaluation.loc[:, ['ID']]\n",
    "result = pd.concat([ID, pd.DataFrame(survived)], axis=1)\n",
    "result.columns = ['ID', 'survived']\n",
    "result.to_csv('result.csv')\n",
    "display(result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
